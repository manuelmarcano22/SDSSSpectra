{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD\n",
    "\n",
    "\n",
    "From the textbook [\"Statistics, Data Mining, and Machine Learning in Astronomy\" (2013)](http://www.astroml.org/book_figures/chapter7/fig_svd_visual.html)\n",
    "![asfda](svd.png)\n",
    "\n",
    "SVD can factorize an $N\\times K$ matrix. The column of U is the *left-singular vector*, and the columns of V are the *right-singular vectors*. The convention used in the book is:\n",
    "\n",
    "$\\Sigma$ is dimention $R \\times R$ where $R = \\min(N,K)$ so $\\Sigma$ is a square matrix $R \\times R$, U is $N\\times R$ and $V^T$ is $R\\times K$. \n",
    "\n",
    "Let's do an example. Lets define a matrix to decompose\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   2.   5.   6.]\n",
      " [  2.   3.   7.   8.]\n",
      " [  6.   7.   9.  50.]]\n",
      "Shape of matrix: (3, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "matrix = np.array([ [1,2,5,6], [2,3,7,8],[6,7,9,50]],dtype='d')\n",
    "print(matrix)\n",
    "print('Shape of matrix: {}'.format(matrix.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can decompose using the [numpy SVD](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.svd.html) function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, D, Vtranspose = np.linalg.svd(matrix,full_matrices=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *full_matrices=False* ensures that the convection stated above is followed. Let's look at the shapes of U, D and V tranpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of U: (3, 3)\n",
      "Shape of V Transpose: (3, 4)\n",
      "Shape of D: (3,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of U: {}'.format(U.shape))\n",
    "print('Shape of V Transpose: {}'.format(Vtranspose.shape))\n",
    "print('Shape of D: {}'.format(D.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So D only return the list of the singular values, so we have to construct the diagonal matrix with *np.diag()*. Let's reconstructe the matrix via multiplication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   2.,   5.,   6.],\n",
       "       [  2.,   3.,   7.,   8.],\n",
       "       [  6.,   7.,   9.,  50.]])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ddiagonal = np.diag(D)\n",
    "np.dot(U.dot(Ddiagonal) , Vtranspose)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that the dimensions of the matrices depend on R. We can try to reconstuct the matrix choosing less singular values $n < R$. So for instant lets reconstruct using the first two singular values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 2\n",
    "Unew = U[:,0:dim]\n",
    "Dnew= D[0:dim]\n",
    "Vtranspose_new = Vtranspose[0:dim,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of new U: (3, 2)\n",
      "Shape of new V Transpose: (2, 4)\n",
      "Shape of new D: (2,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of new U: {}'.format(Unew.shape))\n",
    "print('Shape of new V Transpose: {}'.format(Vtranspose_new.shape))\n",
    "print('Shape of new D: {}'.format(Dn.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets reconstruct the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.29139716,   2.0855279 ,   4.92872996,   5.96590467],\n",
       "       [  1.79958314,   2.9411757 ,   7.04901804,   8.02345005],\n",
       "       [  5.99739176,   6.99923445,   9.00063793,  50.00030518]])"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ddiagonalnew = np.diag(Dnew)\n",
    "np.dot(Unew.dot(Ddiagonalnew) , Vtranspose_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see it is not exact put a good approximation since the highest singular values account for much of the variation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVD with Scikit-learn\n",
    "\n",
    "The same can be achieved using [Truncated SVD](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html) from the scikitlearn package.\n",
    "\n",
    "\n",
    "We defined the dimeinsion and for the algoritm we use arpack to make scikit-learn call the scipy solver for SVD. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "sklearn_svd = TruncatedSVD(n_components=2,algorithm='arpack')\n",
    "svdfit = sklearn_svd.fit(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First two singular values the matrix: [ 53.01701453   6.85938137]\n"
     ]
    }
   ],
   "source": [
    "singularvalues = svdfit.singular_values_\n",
    "print('First two singular values the matrix: {}'.format(singularvalues))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the fit model has a lot of attributes. For example the .components gives you the V transpose matrix up to a sign.\n",
    "\n",
    "> SVD suffers from a problem called “sign indeterminancy”, which means the sign of the components_ and the output from transform depend on the algorithm and random state. To work around this, fit instances of this class to data once, then keep the instance around to do transformations.\n",
    "\n",
    "\n",
    "One also useful information is the *explained_variance_ratio_ *. This represents the **percentage of variance explained by each of the selected components.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11968113  0.14407797  0.20238613  0.96122725]\n",
      " [ 0.11424978  0.27818971  0.92043332 -0.24971981]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.11968113, -0.14407797, -0.20238613, -0.96122725],\n",
       "       [-0.11424978, -0.27818971, -0.92043332,  0.24971981]])"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(svdfit.components_)\n",
    "V[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97846786  0.02142035]\n"
     ]
    }
   ],
   "source": [
    "print(svdfit.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the first component explain much of the variance of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also the mathod transform. This actually returns $U \\times D$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  7.1871312 ,   3.77447691],\n",
       "       [  9.77811705,   5.50834341],\n",
       "       [ 51.60947008,  -1.56926408]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_svd = svdfit.transform(matrix)\n",
    "matrix_svd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -7.1871312 ,  -3.77447691],\n",
       "       [ -9.77811705,  -5.50834341],\n",
       "       [-51.60947008,   1.56926408]])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Unew.dot(Ddiagonalnew)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where again the columns of U are called the **left-singular vectors**. In theory we can now plot this two as the first two principal components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We multiply times V transpose and restore the approximation of the matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.29139716,   2.0855279 ,   4.92872996,   5.96590467],\n",
       "       [  1.79958314,   2.9411757 ,   7.04901804,   8.02345005],\n",
       "       [  5.99739176,   6.99923445,   9.00063793,  50.00030518]])"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(matrix_svd , svdfit.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   2.,   5.,   6.],\n",
       "       [  2.,   3.,   7.,   8.],\n",
       "       [  6.,   7.,   9.,  50.]])"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Value Decomposition and PCA\n",
    "\n",
    "Let's see how this two method compare to each other. In summary:\n",
    "\n",
    "1. The *right-singular vectors* V correspond to the principal components R.\n",
    "2. The diagonal matrix of eigenvalues $C_y$ is equivalent of the singular values square. \n",
    "3. The left singular vectors, U, turn out to be the eigenvectors of the correlation matrix, which has eigenvalues identical to those of the covariance matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2, svd_solver='arpack')\n",
    "pca.fit(matrix)\n",
    "comp = pca.fit_transform(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   7.        ,    7.        ,    5.        ,   65.        ],\n",
       "       [   7.        ,    7.        ,    5.        ,   65.        ],\n",
       "       [   5.        ,    5.        ,    4.        ,   44.        ],\n",
       "       [  65.        ,   65.        ,   44.        ,  617.33333333]])"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.get_covariance()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the matrix we can get it as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   7.        ,    7.        ,    5.        ,   65.        ],\n",
       "       [   7.        ,    7.        ,    5.        ,   65.        ],\n",
       "       [   5.        ,    5.        ,    4.        ,   44.        ],\n",
       "       [  65.        ,   65.        ,   44.        ,  617.33333333]])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot((matrix - mean_vec).T , (matrix - mean_vec))/(matrix.shape[0]-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sure why .T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   7.        ,    7.        ,    5.        ,   65.        ],\n",
       "       [   7.        ,    7.        ,    5.        ,   65.        ],\n",
       "       [   5.        ,    5.        ,    4.        ,   44.        ],\n",
       "       [  65.        ,   65.        ,   44.        ,  617.33333333]])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(matrix.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  3.        ,   4.        ,   7.        ,  21.33333333])"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   7.        ,    7.        ,    5.        ,   65.        ],\n",
       "       [   7.        ,    7.        ,    5.        ,   65.        ],\n",
       "       [   5.        ,    5.        ,    4.        ,   44.        ],\n",
       "       [  65.        ,   65.        ,   44.        ,  617.33333333]])"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "http://sebastianraschka.com/Articles/2015_pca_in_3_steps.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
